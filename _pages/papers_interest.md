---
permalink: /papers-of-interest/
---

## Papers of Interest

For the evaluation of the theoretical aspects of the course, we offer a list of papers of interest which the student may chose to read and review. These are loosely are categorized. For older papers that have been thoroughly review by the community (> 2 years), the student will be expected to focus on novel interpretations of the contribution. 


<a name='history'></a>
### Convolutional Neural Networks

- [Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. "Imagenet classification with deep convolutional neural networks." Advances in neural information processing systems. 2012.] (http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)

- [Zeiler, Matthew D., and Rob Fergus. "Visualizing and understanding convolutional networks." European conference on computer vision. Springer, Cham, 2014.] (https://arxiv.org/pdf/1311.2901v3.pdf)

- [Simonyan, Karen, and Andrew Zisserman. "Very deep convolutional networks for large-scale image recognition." arXiv preprint arXiv:1409.1556 (2014).] (https://arxiv.org/pdf/1409.1556v6.pdf)

- [Lin, Min, Qiang Chen, and Shuicheng Yan. "Network in network." arXiv preprint arXiv:1312.4400 (2013).] (https://arxiv.org/pdf/1312.4400v3.pdf)

- [Szegedy, Christian, et al. "Going deeper with convolutions." Proceedings of the IEEE conference on computer vision and pattern recognition. 2015.] (http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf)

- [He, Kaiming, et al. "Deep residual learning for image recognition." Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.] (https://arxiv.org/pdf/1512.03385v1.pdf)

- [Jaderberg, Max, Karen Simonyan, and Andrew Zisserman. "Spatial transformer networks." Advances in Neural Information Processing Systems. 2015.] (https://arxiv.org/pdf/1506.02025.pdf)

---
The next three papers should be read and reviewed together

- [Girshick, Ross, et al. "Rich feature hierarchies for accurate object detection and semantic segmentation." Proceedings of the IEEE conference on computer vision and pattern recognition. 2014.] (https://arxiv.org/pdf/1311.2524v5.pdf)

- [Girshick, Ross. "Fast r-cnn." Proceedings of the IEEE international conference on computer vision. 2015.] (https://arxiv.org/pdf/1504.08083.pdf)

- [Ren, Shaoqing, et al. "Faster R-CNN: Towards real-time object detection with region proposal networks." Advances in neural information processing systems. 2015.] (http://arxiv.org/pdf/1506.01497v3.pdf)

---

### Generative Adversarial Networks

- [Szegedy, Christian, et al. "Intriguing properties of neural networks." arXiv preprint arXiv:1312.6199 (2013).] (https://arxiv.org/pdf/1312.6199v4.pdf)

- [Goodfellow, Ian, et al. "Generative adversarial nets." Advances in neural information processing systems. 2014.] (http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf)

- [Radford, Alec, Luke Metz, and Soumith Chintala. "Unsupervised representation learning with deep convolutional generative adversarial networks." arXiv preprint arXiv:1511.06434 (2015).] (https://arxiv.org/pdf/1511.06434.pdf)

### Embedding spaces

The next three papers should be read and reviewed together
--------------
- [Mikolov, Tomas, et al. "Efficient estimation of word representations in vector space." arXiv preprint arXiv:1301.3781 (2013).](https://arxiv.org/pdf/1301.3781.pdf)
 
- [Mikolov, Tomas, et al. "Distributed representations of words and phrases and their compositionality." Advances in neural information processing systems. 2013.](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)
 
- [Mikolov, Tomas, Wen-tau Yih, and Geoffrey Zweig. "Linguistic regularities in continuous space word representations." hlt-Naacl. Vol. 13. 2013.](http://www.aclweb.org/anthology/N13-1090)
--------------

- [Rong, Xin. "word2vec parameter learning explained." arXiv preprint arXiv:1411.2738 (2014).] (https://arxiv.org/pdf/1411.2738)

- [Goldberg, Yoav, and Omer Levy. "word2vec Explained: deriving Mikolov et al.'s negative-sampling word-embedding method." arXiv preprint arXiv:1402.3722 (2014).] (https://arxiv.org/pdf/1402.3722)

### Multimodal Pipelines

- [Karpathy, Andrej, and Li Fei-Fei. "Deep visual-semantic alignments for generating image descriptions." Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015.] (https://arxiv.org/pdf/1412.2306v2.pdf)

- [Vinyals, Oriol, et al. "Show and tell: A neural image caption generator." Proceedings of the IEEE conference on computer vision and pattern recognition. 2015.] (http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Vinyals_Show_and_Tell_2015_CVPR_paper.pdf)

- [Kiros, Ryan, Ruslan Salakhutdinov, and Richard S. Zemel. "Unifying visual-semantic embeddings with multimodal neural language models." arXiv preprint arXiv:1411.2539 (2014).] (https://arxiv.org/pdf/1411.2539)

- [Vendrov, Ivan, et al. "Order-embeddings of images and language." arXiv preprint arXiv:1511.06361 (2015).] (https://arxiv.org/pdf/1511.06361.pdf)

### Transfer Learning

- [Yosinski, Jason, et al. "How transferable are features in deep neural networks?." Advances in neural information processing systems. 2014.] (https://arxiv.org/pdf/1411.1792v1.pdf)

- [Sharif Razavian, Ali, et al. "CNN features off-the-shelf: an astounding baseline for recognition." Proceedings of the IEEE conference on computer vision and pattern recognition workshops. 2014.] (https://arxiv.org/pdf/1403.6382.pdf)

### Recurrent Neural Networks

-  [Alex Graves Generating Sequences With Recurrent Neural Networks](https://arxiv.org/pdf/1308.0850)


- [Kyunghyun Cho, Bart van Berrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio, Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation, arXiv:1406.1078 / EMNLP 2014](http://arxiv.org/pdf/1406.1078)

 - [Ilya Sutskever, Oriol Vinyals, and Quoc V. Le, Sequence to Sequence Learning with Neural Networks, arXiv:1409.3215 / NIPS 2014](http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)

 - [A.Graves, G. Wayne, and I. Danihelka., Neural Turing Machines, arXiv preprint arXiv:1410.5401](http://arxiv.org/pdf/1410.5401)

 - [Mike Schuster and Kuldip K. Paliwal, Bidirectional Recurrent Neural Networks, Trans. on Signal Processing 1997](http://www.di.ufpe.br/%7Efnj/RNA/bibliografia/BRNN.pdf)

  - [Nal Kalchbrenner, Ivo Danihelka, and Alex Graves, Grid Long Short-Term Memory, arXiv:1507.01526](http://arxiv.org/pdf/1507.01526)

  - [Kai Sheng Tai, Richard Socher, and Christopher D. Manning, Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks, arXiv:1503.00075 / ACL 2015](http://arxiv.org/pdf/1503.00075)

  - [Ankit Kumar, Ozan Irsoy, Peter Ondruska, Mohit Iyyer, James Bradbury, Ishaan Gulrajani, Victor Zhong, Romain Paulus, Richard Socher, "Ask Me Anything: Dynamic Memory Networks for Natural Language Processing"](http://arxiv.org/abs/1506.07285)

### Theory of Deep Learning

- [Shwartz-Ziv, Ravid, and Naftali Tishby. "Opening the Black Box of Deep Neural Networks via Information."](https://arxiv.org/abs/1703.00810)

- [Neurosurgeon: Collaborative Intelligence Between the Cloud and Mobile Edge. ASPLOS 2017: 615-629] (http://web.eecs.umich.edu/~jahausw/publications/kang2017neurosurgeon.pdf)

- [Norman P. Jouppi, Cliff Young, Nishant Patil, David Patterson, et al. In-Datacenter Performance Analysis of a Tensor Processing Unit. ISCA 2017: 1-12] (https://arxiv.org/abs/1704.04760)

- [Tianshi Chen, Zidong Du, Ninghui Sun, Jia Wang, Chengyong Wu, Yunji Chen, Olivier Temam:
DianNao: a small-footprint high-throughput accelerator for ubiquitous machine-learning. ASPLOS 2014: 269-284] (http://novel.ict.ac.cn/ychen/pdf/DianNao.pdf)

- [Ammar Ahmad Awan, Khaled Hamidouche, Jahanzeb Maqbool Hashmi, Dhabaleswar K. Panda:
S-Caffe: Co-designing MPI Runtimes and Caffe for Scalable Deep Learning on Modern GPU Clusters. PPOPP 2017: 193-205] (https://dl.acm.org/citation.cfm?id=3018769&dl=ACM&coll=DL&CFID=995532436&CFTOKEN=69605876)

- [Muhammet Mustafa Ozdal, Serif Yesil, Taemin Kim, Andrey Ayupov, John Greth, Steven M. Burns, Özcan Özturk:
Energy Efficient Architecture for Graph Analytics Accelerators. ISCA 2016: 166-177] (https://dl.acm.org/citation.cfm?id=3001155)
